### 말말말 Repository

팀원 : 임보혁(Leader), 이상진, 문건호, 박정훈, 안선모

---

1.  데이터 시각화

[] 문장 길이(토큰 수) 분포

각 클래스별로 평균·최대·분산 확인.

“협박”류는 짧고 단호, “직장 내 괴롭힘”은 길고 복합적일 가능성.

모델 입력 시 max_length 결정 근거로 사용.

[] 감정/공격성 스코어 분포

긍정·중립·부정 스코어를 비교해 감정 강도 차이 분석.

위협/갈취 클래스는 부정·공격성이 높게 분포하는지 확인.

감정적 톤의 경계를 시각적으로 파악해 라벨링 검증.

[] TF-IDF / WordCloud 시각화

각 클래스의 주요 단어·표현 패턴 도출.

위협·갈취: ‘돈’, ‘죽’, ‘가만안둬’ 등 핵심 어휘가 집중될 것.

일반 대화: ‘좋다’, ‘같아’, ‘주말’ 등 감정 완화형 어휘 중심.

[] 임베딩 시각화 (2D/3D)

BERT/SBERT 임베딩 후 t-SNE·UMAP으로 차원 축소.

각 클래스의 군집 분리 여부 시각적으로 확인.

데이터 간 경계(위협 vs 일반)가 실제로 존재하는지 파악.

1.  전처리 전략
    [] 핵심 포인트: 줄바꿈 처리 일관화

문제: train은 여러 턴(\n) 포함, test는 한 줄짜리 문장.

전략 1: train의 줄바꿈 제거 → 전체를 문맥 단위로 통일.

전략 2: test 포맷에 맞게 train의 대화 줄바꿈을 유지하되, 구분 토큰(</s>)으로 대체.

전략 3: 일반 대화(한 줄) 데이터에는 임의의 줄바꿈을 추가하여 균형 확보.

최종 결정: 학습·추론 포맷을 동일하게 유지해야 함.

3.  데이터 증강 (Augmentation)
    [] 표면적 증강 (Surface-level)

Back-Translation: 한국어→영어→한국어로 어순 다양화.

동의어·형태 치환: 감정 유지하며 어휘만 변경.

[] 의미 기반 증강 (Semantic-level)

대화의 주제나 맥락은 유지, 표현만 다르게 재작성.

예: “빨리 돈 갚아” → “언제쯤 정리할 수 있을까?”

[] 공격성 강도 조절 (Threat-level Scaling)

동일한 문장을 3단계(High/Medium/Low) 강도로 재구성.

“죽인다” → “가만 안 둬” → “후회하게 될 거야”.

[] 노이즈 기반 증강 (Noise Injection)

실제 대화체 반영: 띄어쓰기 오류, 감탄사, 반복어 삽입.

“야진짜너무열받는다” / “ㄹㅇ어이없음ㅋㅋ”.

4.  모델 설계 및 비교

    모델 개요 장점 단점

    ① 프리트레인 모델 (KoBERT, KLUE-RoBERTa 등) 공개된 한국어 BERT 계열 빠른 수렴, 강한 언어 이해력 커스텀 문체 대응 약함

    ② 직접 구현한 BERT (Scratch) Embedding → MultiHead Attention → FFN 구조 이해 및 제어 용이 학습 비용 큼

    ③ LRP with LSTM LRP(Locally Recurrent Projection) + LSTM 결합 구조 문맥 기반 reasoning 가능 fine-tuning 난이도 높음

## **사전학습 모델 임베딩과 그렇지않은 모델의 임베딩 차이**

### 과제 개요

- **목표:** 대화의 성격을 5개 클래스 중 하나로 분류
  - 위협 세부 클래스 4개: `협박`, `갈취`, `직장 내 괴롭힘`, `기타 괴롭힘`
  - 비위협 클래스: `일반 대화`

---

### 데이터 구성

- **Train 데이터:**
  - `협박`, `갈취`, `직장 내 괴롭힘`, `기타 괴롭힘` — 각 약 1,000개
  - `일반 대화` — 합성 데이터로 직접 생성 (다양한 프롬프트 기반)
- **Test 데이터:**
  - `협박`, `갈취`, `직장 내 괴롭힘`, `기타 괴롭힘`, `일반 대화` — 각 100개

---

### 제약 조건

- 위협 클래스 4종은 **Augmentation만 가능**  
  (새로운 수집/생성 불가)
- `일반 대화` 클래스는 **합성 데이터 생성 필수**
- 최종 제출 결과는 **합성 데이터 기반 성능**만 인정
- **증강된 데이터는 (새로운 데이터 추가/생성 불가)에 해당되지 않는다.**

---

### 실험 및 분석 방향

1. **합성 데이터 생성 및 활용 (필수)**
   - 다양한 프롬프트를 이용한 문장 생성
   - 품질 필터링 및 후처리 전략 수립
2. **기 확보된 데이터 활용**
   - 예: AI Hub 등 외부 공개 데이터 병합
   - 추가 실험을 통한 일반화 성능 비교
3. **모델 성능 향상 요인 탐색**
   - 데이터 비율 조정, 클래스 불균형 해소
   - 토크나이저/임베딩 기법 비교
   - 하이퍼파라미터 튜닝 영향 분석
4. **Ablation Study 형식으로 결과 기록**
   - 각 실험 조건별 성능 비교 (예: F1-score, Accuracy)
   - 데이터셋 변화 또는 학습 설정 변화에 따른 영향 명시

---

## **DATA Files**

- train.csv - DKTC 학습 데이터셋
- test.csv - DKTC 테스트 데이터셋
- submission.csv - 테스트데이터셋에 맞는 샘플 제출 csv파일

## **Columns**

- idx - 학습 데이터셋 인덱스번호
- class - 라벨
- conversation - 대화

## **클래스 분류 및 클래스 개수**

| **클래스**     | **Class No.** | **# Training** | **# Test** |
| -------------- | ------------- | -------------- | ---------- |
| 협박           | 00            | 896            | 100        |
| 갈취           | 01            | 981            | 100        |
| 직장 내 괴롭힘 | 02            | 979            | 100        |
| 기타 괴롭힘    | 03            | 1,094          | 100        |
| 일반           | 04            | -              | 100        |

**submission.csv 의 class 출력은 숫자로 되어야함.**

---

### 평가 기준

- **데이터 EDA와 전처리를 적절히 수행했는가?**

- **모델 선정 근거가 타당한가?**

- **모델의 성능/학습 방향을 판단하고 개선을 시도한 기준이 논리적인가?**

- **결과 도출을 위해 다양한 시도를 했는가?**

- **도출된 결론에 충분한 설득력이 있는가?**

- **발표 자료가 청자의 입장에서 잘 정리되어있는가?**

- **발표가 매끄럽게 진행되었고 발표시간을 준수하였는가?**
