### 말말말 Repository

팀원 : 임보혁(Leader), 이상진, 문건호, 박정훈, 안선모

---

Task: 대화 데이터(협박·갈취·직장 내 괴롭힘·기타 괴롭힘·일반 대화) 분류

모델 후보:

pretrained-BERT

pretrained-BERT-CNN

직접 구현 BERT

직접 구현 RSTM

Text-CNN

결과: pretrained-BERT-CNN 최고 성능 (Public LB 0.74)

이슈: 일반 대화가 너무 쉬워 99% 이상 분류 → 데이터 불균형 및 단순 키워드 의존 가능성

1️ 데이터 EDA 및 전처리 수행 근거
분석 항목방법결과 요약문장 길이토큰 수 분포 시각화대부분 20~60 토큰 사이, 클래스 간 큰 차이 없음단어 빈도TF-IDF 기반 단어 중요도각 클래스별 키워드 명확 (예: “돈”, “내놔” → 갈취 / “팀장”, “보고” → 직장 내 괴롭힘)공격성 스코어감정·공격성 사전 적용협박·갈취는 높은 감정 스코어, 일반대화는 낮음임베딩 시각화PCA/TSNE키워드형 클래스는 경계 뚜렷, 문맥형은 중첩 영역 다수
결론:
클래스 구분 신호가 **국소적(local)**이며, 문맥 기반보다는 키워드 중심 분류 신호가 강함 → CNN 적합.

2️모델 선정 근거
모델구조 요약적합성 판단BERT문맥형 feature 강함키워드형 클래스에 비효율Text-CNN단어 n-gram 기반문맥형 데이터에 약함BERT-CNNBERT + Conv1DBERT의 contextual feature + CNN의 국소 패턴 탐지 결합RSTMRNN 기반 순차 처리문맥형엔 적합하나 학습비용 높고 성능 열세
📌 선정 이유:

BERT hidden state에서 Conv1D를 통해 n-gram 단위 국소패턴 강화

“협박” “갈취”와 같은 키워드형 클래스에서 강력한 구분 성능

미묘한 문맥 구분(직장 내 괴롭힘 vs 일반 대화)은 클래스 가중치 보정으로 해결

3️모델 성능 및 개선 방향 판단 기준
시도목적결과CE vs Weighted CE문맥형 클래스 보정F1 향상 약 +0.02Augmentation (BertAug)데이터 다양화성능 향상 0.71 → 0.74CNN kernel size 다양화다양한 n-gram 반영최적값: kernel [2,3,4]Dropout, LR 조정과적합 방지일반대화 정확도 유지하며 균형 개선
📌 논리:
성능 향상 시도는 문맥형 클래스 구분력 강화에 집중.

4️다양한 시도 및 실험 정리
실험명핵심 변화F1 Scorebaseline-BERT기본 CE loss0.68weighted-BERTclass weight 적용0.70pretrained-BERT-CNNConv1D 추가0.73pretrained-BERT-CNN + Aug증강 데이터 포함0.74

5️ 결론의 설득력

정량적 근거:

실험 반복 5회 평균 F1 일관 유지 (±0.005)

augmentation 및 class-weight 조합 효과 검증

정성적 근거:

TF-IDF 분석으로 “국소적 신호” 존재 증명

모델 구조와 데이터 특성 간 논리적 일치

결론 요약:

“문맥형보다는 키워드형 클래스가 주를 이루는 데이터 구조에 따라
BERT의 contextual representation에 CNN의 local filter를 결합한 모델이
가장 타당하고 효과적이었다.”

6️발표 구성 (청자 관점)
파트내용발표자1. 문제 정의 및 데이터 EDA데이터 특성·클래스별 키워드 시각화팀원 A2. 모델 구조 비교5개 모델 구조 및 장단점팀원 B3. 실험 결과 및 개선 과정augmentation·class-weight 실험팀원 C4. 결론 및 제언모델 선택 논리·향후 방향팀원 D

7️ 발표용 핵심 메시지 정리

“우리 데이터는 문맥보다 키워드로 구분되는 경향이 뚜렷했습니다.
따라서 BERT의 문맥 표현력 위에 CNN의 국소 패턴 검출을 결합한
pretrained-BERT-CNN이 가장 적합한 선택이었습니다.”

---

## **사전학습 모델 임베딩과 그렇지않은 모델의 임베딩 차이** project05 참조

### 과제 개요

- **목표:** 대화의 성격을 5개 클래스 중 하나로 분류
  - 위협 세부 클래스 4개: `협박`, `갈취`, `직장 내 괴롭힘`, `기타 괴롭힘`
  - 비위협 클래스: `일반 대화`

---

### 데이터 구성

- **Train 데이터:**
  - `협박`, `갈취`, `직장 내 괴롭힘`, `기타 괴롭힘` — 각 약 1,000개
  - `일반 대화` — 합성 데이터로 직접 생성 (다양한 프롬프트 기반)
- **Test 데이터:**
  - `협박`, `갈취`, `직장 내 괴롭힘`, `기타 괴롭힘`, `일반 대화` — 각 100개

---

### 제약 조건

- 위협 클래스 4종은 **Augmentation만 가능**  
  (새로운 수집/생성 불가)
- `일반 대화` 클래스는 **합성 데이터 생성 필수**
- 최종 제출 결과는 **합성 데이터 기반 성능**만 인정
- **증강된 데이터는 (새로운 데이터 추가/생성 불가)에 해당되지 않는다.**

---

### 실험 및 분석 방향

1. **합성 데이터 생성 및 활용 (필수)**
   - 다양한 프롬프트를 이용한 문장 생성
   - 품질 필터링 및 후처리 전략 수립
2. **기 확보된 데이터 활용**
   - 예: AI Hub 등 외부 공개 데이터 병합
   - 추가 실험을 통한 일반화 성능 비교
3. **모델 성능 향상 요인 탐색**
   - 데이터 비율 조정, 클래스 불균형 해소
   - 토크나이저/임베딩 기법 비교
   - 하이퍼파라미터 튜닝 영향 분석
4. **Ablation Study 형식으로 결과 기록**
   - 각 실험 조건별 성능 비교 (예: F1-score, Accuracy)
   - 데이터셋 변화 또는 학습 설정 변화에 따른 영향 명시

---

## **DATA Files**

- train.csv - DKTC 학습 데이터셋
- test.csv - DKTC 테스트 데이터셋
- submission.csv - 테스트데이터셋에 맞는 샘플 제출 csv파일

## **Columns**

- idx - 학습 데이터셋 인덱스번호
- class - 라벨
- conversation - 대화

## **클래스 분류 및 클래스 개수**

| **클래스**     | **Class No.** | **# Training** | **# Test** |
| -------------- | ------------- | -------------- | ---------- |
| 협박           | 00            | 896            | 100        |
| 갈취           | 01            | 981            | 100        |
| 직장 내 괴롭힘 | 02            | 979            | 100        |
| 기타 괴롭힘    | 03            | 1,094          | 100        |
| 일반           | 04            | -              | 100        |

**submission.csv 의 class 출력은 숫자로 되어야함.**

---

### 평가 기준

- **데이터 EDA와 전처리를 적절히 수행했는가?**

- **모델 선정 근거가 타당한가?**

- **모델의 성능/학습 방향을 판단하고 개선을 시도한 기준이 논리적인가?**

- **결과 도출을 위해 다양한 시도를 했는가?**

- **도출된 결론에 충분한 설득력이 있는가?**

- **발표 자료가 청자의 입장에서 잘 정리되어있는가?**

- **발표가 매끄럽게 진행되었고 발표시간을 준수하였는가?**
