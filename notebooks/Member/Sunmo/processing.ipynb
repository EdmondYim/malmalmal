{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "645a4fac",
   "metadata": {},
   "source": [
    "### STEP 1 RAW 데이터 불러오기\n",
    "원본 train 데이터인 train.csv와 우리 팀이 생성한 일반데이터인 'general.csv'를 불러와 'train_general_combined.csv'로 병합합니다.\n",
    "\n",
    "'train_general_combined.csv' 데이터는 /output/ 내에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dc2d52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 병합 완료! 저장 경로: ./output/train_general_combined.csv\n",
      "총 행 개수: 4750\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "train = pd.read_csv(\"./filestore_raw/train.csv\")     # 첫 번째 CSV\n",
    "general = pd.read_csv(\"./filestore_raw/general.csv\") # 두 번째 CSV\n",
    "\n",
    "# 두 DataFrame 합치기 (train 다음에 general)\n",
    "combined = pd.concat([train, general], ignore_index=True)\n",
    "\n",
    "output_path = \"./output/train_general_combined.csv\"\n",
    "combined.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ 병합 완료! 저장 경로: {output_path}\")\n",
    "print(f\"총 행 개수: {len(combined)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d375b38",
   "metadata": {},
   "source": [
    "### STEP2 데이터를 로드하기\n",
    "csv에서 판다스로 데이터를 로드하고 기본 통계와 줄바꿈 패턴을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3988f762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "전체 데이터 수: 4,750개\n",
      "컬럼: ['idx', 'class', 'conversation']\n",
      "\n",
      "클래스 분포:\n",
      "class\n",
      "기타 괴롭힘 대화      1094\n",
      "갈취 대화           981\n",
      "직장 내 괴롭힘 대화     979\n",
      "협박 대화           896\n",
      "일반              800\n",
      "Name: count, dtype: int64\n",
      "\n",
      "줄바꿈 통계:\n",
      "\n",
      "- 줄바꿈 없는 데이터: 800개\n",
      "- 줄바꿈 있는 데이터: 3,950개\n",
      "✅ 로드 완료\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from typing import List\n",
    "import random\n",
    "\n",
    "# 랜덤 시드 고정 (재현성)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "df = pd.read_csv('./output/train_general_combined.csv')\n",
    "\n",
    "print(f\"\\n전체 데이터 수: {len(df):,}개\")\n",
    "print(f\"컬럼: {df.columns.tolist()}\")\n",
    "print(f\"\\n클래스 분포:\")\n",
    "print(df['class'].value_counts())\n",
    "\n",
    "# 줄바꿈 패턴 분석\n",
    "df['newline_count'] = df['conversation'].str.count('\\n')\n",
    "print(f\"\\n줄바꿈 통계:\")\n",
    "print(f\"\\n- 줄바꿈 없는 데이터: {(df['newline_count'] == 0).sum():,}개\")\n",
    "print(f\"- 줄바꿈 있는 데이터: {(df['newline_count'] > 0).sum():,}개\")\n",
    "\n",
    "print(f\"✅ 로드 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ffae5c",
   "metadata": {},
   "source": [
    "### STEP3. 전처리 함수를 정의합니다.\n",
    "*여러 방법을 실험하여 최적의 방법을 찾을 수 있도록 세가지 방법으로 전처리하였습니다.*\n",
    "\n",
    "(1) 줄바꿈을 완전 제거하여 한 줄로 만들기 -> 줄바꿈을 공백으로 대체합니다.\n",
    "- 모든 줄바꿈(\\n)을 공백으로 대체하고 공백이 복수 개인 경우 단일 공백으로 대체합니다.\n",
    "- 이 경우에는 추후 TEST데이터 분석시에도 동일하게 줄바꿈을 공백으로 대체하여 test해야 할 것으로 보입니다.\n",
    "\n",
    "(2) 줄바꿈을 구분 토큰인 [SEP]로 대체\n",
    "- 줄바꿈(\\n)을 특수 구분 토큰(기본값: [SEP])으로 대체\n",
    "- 대화 턴의 구조 정보 보존\n",
    "- 모델이 턴 구분을 학습할 수 있도록 함\n",
    "    \n",
    "(3) GPT로 생성된 일반 대화 데이터에 임의 줄바꿈 추가\n",
    "- 단일 문장 데이터를 문장 부호(., ?, !) 기준으로  여러 줄로 분할\n",
    "- 데이터 균형 확보 (train과 test 간 포맷 차이 완화)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "760dea10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 전처리 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "\"\"\" [전략1] \"\"\"\n",
    "def preprocess_strategy_1(text: str) -> str:\n",
    "\n",
    "    # 줄바꿈을 공백으로 대체\n",
    "    processed = text.replace('\\n', ' ')\n",
    "    \n",
    "    # 다중 공백을 단일 공백으로 정리\n",
    "    processed = re.sub(r'\\s+', ' ', processed)\n",
    "    \n",
    "    # 앞뒤 공백 제거\n",
    "    processed = processed.strip()\n",
    "    \n",
    "    return processed\n",
    "\n",
    "\"\"\" [전략2] \"\"\"\n",
    "import re\n",
    "\n",
    "def preprocess_strategy_2(text: str, separator: str = '[SEP]') -> str:\n",
    "    \"\"\"\n",
    "    - 텍스트에 줄바꿈(\\n)이 하나라도 있으면: 줄바꿈만 구분자로 사용.\n",
    "    - 줄바꿈이 전혀 없으면: 문장 끝 문장부호(.!?… 등) 뒤에 구분자 삽입.\n",
    "    - 결과는 중복된 구분자와 과도한 공백을 정리한 한 줄 문자열로 반환.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return ''\n",
    "\n",
    "    # Normalize newlines\n",
    "    t = text.replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "\n",
    "    if '\\n' in t:\n",
    "        # 줄바꿈만 구분자로 처리 (연속 줄바꿈은 하나로)\n",
    "        processed = re.sub(r'\\n+', f' {separator} ', t)\n",
    "    else:\n",
    "        # 줄바꿈 없음 -> 문장부호 기준으로 분리\n",
    "        # 문장부호 뒤에 구분자 추가 (따옴표/괄호 닫힘 포함)\n",
    "        processed = re.sub(\n",
    "            r'([\\.!?。！？…]+)([)\"\\'”’\\]]*)\\s*',\n",
    "            rf'\\1\\2 {separator} ',\n",
    "            t\n",
    "        )\n",
    "\n",
    "    # 연속된 구분자/공백을 하나로 축약\n",
    "    processed = re.sub(rf'(?:\\s*{re.escape(separator)}\\s*)+', f' {separator} ', processed)\n",
    "    # 다중 공백 정리 및 앞뒤 공백 제거\n",
    "    processed = re.sub(r'\\s+', ' ', processed).strip()\n",
    "\n",
    "    return processed\n",
    "\n",
    "\n",
    "\"\"\" [전략3] \"\"\"\n",
    "def add_random_newlines(text: str, min_lines: int = 3, max_lines: int = 10) -> str:\n",
    "\n",
    "    # 이미 줄바꿈이 충분히 있으면 그대로 반환\n",
    "    if text.count('\\n') >= min_lines:\n",
    "        return text\n",
    "    \n",
    "    # 문장 부호 기준으로 분할 가능한 위치 찾기\n",
    "    sentences = re.split(r'([.?!]\\s+)', text)\n",
    "    \n",
    "    # 분할 결과가 너무 적으면 원본 반환\n",
    "    if len(sentences) < 3:\n",
    "        return text\n",
    "    \n",
    "    # 문장과 구분자 재조합\n",
    "    reconstructed = []\n",
    "    for i in range(0, len(sentences)-1, 2):\n",
    "        if i+1 < len(sentences):\n",
    "            reconstructed.append(sentences[i] + sentences[i+1].strip())\n",
    "        else:\n",
    "            reconstructed.append(sentences[i])\n",
    "    \n",
    "    # 마지막 요소 처리\n",
    "    if len(sentences) % 2 == 1:\n",
    "        reconstructed.append(sentences[-1])\n",
    "    \n",
    "    # 줄바꿈 추가할 개수 결정\n",
    "    num_newlines = min(random.randint(min_lines, max_lines), len(reconstructed)-1)\n",
    "    \n",
    "    # 랜덤하게 줄바꿈 삽입\n",
    "    if len(reconstructed) > 1:\n",
    "        # 줄바꿈 위치 랜덤 선택\n",
    "        split_indices = sorted(random.sample(range(1, len(reconstructed)), \n",
    "                                           min(num_newlines, len(reconstructed)-1)))\n",
    "        \n",
    "        result_parts = []\n",
    "        prev_idx = 0\n",
    "        for idx in split_indices:\n",
    "            result_parts.append(' '.join(reconstructed[prev_idx:idx]))\n",
    "            prev_idx = idx\n",
    "        result_parts.append(' '.join(reconstructed[prev_idx:]))\n",
    "        \n",
    "        return '\\n'.join(result_parts)\n",
    "    \n",
    "    return text\n",
    "\n",
    "print(f\"✅ 전처리 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0de11a6",
   "metadata": {},
   "source": [
    "### STEP 4. 전처리를 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94d21a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 전략 1 완료\n",
      "✅ 전략 2 완료\n",
      "✅ 전략3 완료\n",
      "\n",
      "✅ 전처리 완료!\n"
     ]
    }
   ],
   "source": [
    "# 전략 1: 줄바꿈 완전 제거\n",
    "df_strategy1 = df.copy()\n",
    "df_strategy1['conversation_processed'] = df_strategy1['conversation'].apply(preprocess_strategy_1)\n",
    "print(f\"✅ 전략 1 완료\")\n",
    "\n",
    "# 전략 2: 구분 토큰으로 대체\n",
    "df_strategy2 = df.copy()\n",
    "df_strategy2['conversation_processed'] = df_strategy2['conversation'].apply(\n",
    "    lambda x: preprocess_strategy_2(x, separator='[SEP]')\n",
    ")\n",
    "print(f\"✅ 전략 2 완료\")\n",
    "\n",
    "\n",
    "# 전략 3: 일반 대화에 줄바꿈 추가\n",
    "df_strategy3 = df.copy()\n",
    "\n",
    "# 일반 대화(줄바꿈 없는 데이터)에만 줄바꿈 추가\n",
    "mask_general = df_strategy3['newline_count'] == 0\n",
    "df_strategy3.loc[mask_general, 'conversation_processed'] = df_strategy3.loc[mask_general, 'conversation'].apply(\n",
    "    add_random_newlines\n",
    ")\n",
    "df_strategy3.loc[~mask_general, 'conversation_processed'] = df_strategy3.loc[~mask_general, 'conversation']\n",
    "print(f\"✅ 전략3 완료\")\n",
    "\n",
    "print(\"\\n✅ 전처리 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4db63e7",
   "metadata": {},
   "source": [
    "### STEP4-1. 클래스별 줄바꿈 비율 맞추기\n",
    "전략 3 결과가 만들어진 뒤, 클래스마다 절반은 줄바꿈 상태를 유지/추가하고 나머지는 줄바꿈을 제거해 포맷 균형을 맞춥니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81f2bbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             newline_rows  total_rows  no_newline_rows\n",
      "class                                                 \n",
      "갈취 대화                 491         981              490\n",
      "기타 괴롭힘 대화             547        1094              547\n",
      "일반                    400         800              400\n",
      "직장 내 괴롭힘 대화           490         979              489\n",
      "협박 대화                 448         896              448\n",
      "✅ 클래스별 줄바꿈/무줄바꿈 분배 완료\n"
     ]
    }
   ],
   "source": [
    "# 전략 3 결과에서 클래스별 줄바꿈/무줄바꿈을 균형 있게 분배\n",
    "df_strategy3['conversation_processed'] = df_strategy3['conversation_processed'].fillna('')\n",
    "rng = np.random.RandomState(42)\n",
    "for cls_value, idx in df_strategy3.groupby('class').groups.items():\n",
    "    cls_indices = np.array(list(idx))\n",
    "    if len(cls_indices) == 0:\n",
    "        continue\n",
    "    rng.shuffle(cls_indices)\n",
    "    newline_count = int(np.ceil(len(cls_indices) / 2))\n",
    "    newline_idx = cls_indices[:newline_count]\n",
    "    flat_idx = cls_indices[newline_count:]\n",
    "    df_strategy3.loc[newline_idx, 'conversation_processed'] = (\n",
    "        df_strategy3.loc[newline_idx, 'conversation_processed']\n",
    "        .apply(add_random_newlines)\n",
    "    )\n",
    "    df_strategy3.loc[flat_idx, 'conversation_processed'] = (\n",
    "        df_strategy3.loc[flat_idx, 'conversation_processed']\n",
    "        .apply(preprocess_strategy_1)\n",
    "    )\n",
    "\n",
    "newline_stats = (\n",
    "    df_strategy3.assign(\n",
    "        has_newline=df_strategy3['conversation_processed'].str.contains('\\n', regex=False)\n",
    "    )\n",
    "    .groupby('class')['has_newline']\n",
    "    .agg(['sum', 'count'])\n",
    ")\n",
    "newline_stats.rename(columns={'sum': 'newline_rows', 'count': 'total_rows'}, inplace=True)\n",
    "newline_stats['no_newline_rows'] = newline_stats['total_rows'] - newline_stats['newline_rows']\n",
    "print(newline_stats)\n",
    "print('✅ 클래스별 줄바꿈/무줄바꿈 분배 완료')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d2cdcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### STEP 5 전처리 데이터를 csv로 출력합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fb5680e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ 전략 1 저장 완료: ./output/train_strategy1_remove_newlines.csv\n",
      "✅  전략 2 저장 완료: ./output/train_strategy2_separator_token.csv\n",
      "✅  전략 3 저장 완료: ./output/train_strategy3_add_random_newlines.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 각 전략별 저장\n",
    "output_columns = ['idx', 'class', 'conversation_processed']\n",
    "\n",
    "df_strategy1_output = df_strategy1[output_columns].rename(\n",
    "    columns={'conversation_processed': 'conversation'}\n",
    ")\n",
    "df_strategy1_output.to_csv('./output/train_strategy1_remove_newlines.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"\\n✓ 전략 1 저장 완료: ./output/train_strategy1_remove_newlines.csv\")\n",
    "\n",
    "df_strategy2_output = df_strategy2[output_columns].rename(\n",
    "    columns={'conversation_processed': 'conversation'}\n",
    ")\n",
    "df_strategy2_output.to_csv('./output/train_strategy2_separator_token.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"✅  전략 2 저장 완료: ./output/train_strategy2_separator_token.csv\")\n",
    "\n",
    "df_strategy3_output = df_strategy3[output_columns].rename(\n",
    "    columns={'conversation_processed': 'conversation'}\n",
    ")\n",
    "df_strategy3_output.to_csv('./output/train_strategy3_add_random_newlines.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"✅  전략 3 저장 완료: ./output/train_strategy3_add_random_newlines.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3197e1",
   "metadata": {},
   "source": [
    "**전략1(줄바꿈 완전 제거)**은 모든 줄바꿈을 공백으로 대체하고 다중 공백을 단일 공백으로 정규화하는 방식입니다. 이 방법은 테스트 데이터의 형식과 가장 일치하며(줄바꿈 없음 비율 100% vs 테스트 95.2%), 대화의 순서와 내용을 완벽하게 보존합니다. 예를 들어 \"지금 너 스스로를 죽여달라고 애원하는 것인가?\\n아닙니다\"는 \"지금 너 스스로를 죽여달라고 애원하는 것인가? 아닙니다\"로 변환되어 의미와 순서가 그대로 유지됩니다. 구현이 단순하고 재현 가능하며, 추론 시에도 테스트 데이터에 동일한 전처리를 적용하기만 하면 되어 운영 측면에서도 안정적입니다.\n",
    "\n",
    "**전략2([SEP] 토큰 대체)**는 줄바꿈을 특수 구분 토큰으로 치환하여 대화 턴의 구조 정보를 명시적으로 보존하는 방식입니다. 평균 9.3개의 [SEP] 토큰이 삽입되어 \"아닙니다. [SEP] 죄송합니다. [SEP]\"와 같은 형태를 만듭니다. 이 방법은 BERT 계열 모델이 학습 시 사용하는 문장 구분 방식과 유사하여, 사전학습된 언어모델의 구조적 이해를 활용할 수 있다는 장점이 있습니다. 그러나 평균 길이가 260.4자로 원본 대비 26% 증가하여 학습 및 추론 비용이 상승하며, 모델의 어휘집에 [SEP] 토큰이 포함되어 있지 않으면 효과가 제한적일 수 있습니다. 문장 부호 기준 분할 로직도 복잡하여 예외 처리가 필요합니다.\n",
    "\n",
    "**전략3(랜덤 줄바꿈 추가)**는 일반 대화 800개에 문장 부호 기준으로 3~10개의 랜덤 줄바꿈을 추가하는 방식입니다. 일반 데이터의 줄바꿈 수를 0에서 5.59로 증가시켜 괴롭힘 데이터와 형식을 맞추려는 시도이나, 이는 테스트 데이터 형식과 정반대 방향입니다. 테스트 데이터는 95.2%가 줄바꿈 없는데 학습 데이터를 모두 줄바꿈 포함 형태로 만들면 분포 불일치가 더욱 심화됩니다. 또한 random.seed(42)로 재현성을 확보했다 해도, 인위적으로 삽입된 줄바꿈 위치는 자연스러운 대화 흐름을 반영하지 못하며, 모델이 이러한 인공적 패턴을 학습하면 실제 테스트 환경에서 성능이 저하될 위험이 큽니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4927170f",
   "metadata": {},
   "source": [
    "### [전략 평가]\n",
    "**전략1(줄바꿈 완전 제거)** 은 모든 줄바꿈을 공백으로 대체하고 다중 공백을 단일 공백으로 정규화하는 방식입니다. 이 방법은 테스트 데이터의 형식과 가장 일치하며, 대화의 순서와 내용을 완벽하게 보존합니다. 예를 들어 \"지금 너 스스로를 죽여달라고 애원하는 것인가?\\n아닙니다\"는 \"지금 너 스스로를 죽여달라고 애원하는 것인가? 아닙니다\"로 변환되어 의미와 순서가 그대로 유지됩니다. 구현이 단순하고 재현 가능하며, 추론 시에도 테스트 데이터에 동일한 전처리를 적용하기만 하면 되어 운영 측면에서도 안정적입니다.\n",
    "\n",
    "전략1(줄바꿈 제거)의 타당성은 매우 높습니다. 테스트 데이터가 줄바꿈 없는 형태로 제공되는 상황에서, 학습 데이터를 동일한 형식으로 정규화하는 것은 필수적입니다. Train-Test 분포 일치는 머신러닝 모델 성능의 핵심 전제이며, 정보 손실 없이 이를 달성하는 전략1이 최선의 선택입니다. 실제 추론 환경에서도 입력 데이터에 동일한 전처리(줄바꿈 제거)만 적용하면 되어 파이프라인이 단순하고 안정적입니다.\n",
    "\n",
    "**전략2([SEP] 토큰 대체)** 는 줄바꿈을 특수 구분 토큰으로 치환하여 대화 턴의 구조 정보를 명시적으로 보존하는 방식입니다. 평균 9.3개의 [SEP] 토큰이 삽입되어 \"아닙니다. [SEP] 죄송합니다. [SEP]\"와 같은 형태를 만듭니다. 이 방법은 BERT 계열 모델이 학습 시 사용하는 문장 구분 방식과 유사하여, 사전학습된 언어모델의 구조적 이해를 활용할 수 있다는 장점이 있습니다. 그러나 평균 길이가 260.4자로 원본 대비 26% 증가하여 학습 및 코드 실행시 복잡도(더 많은 시간과 자원 소모)가 상승하며, 모델의 어휘집에 [SEP] 토큰이 포함되어 있지 않으면 효과가 제한적일 수 있습니다. 문장 부호 기준 분할 로직도 복잡하여 예외 처리가 필요합니다.\n",
    "\n",
    "전략2([SEP] 토큰)의 타당성은 제한적입니다. 대화 턴 구조를 보존하려는 의도는 좋으나, 실제 테스트 데이터에는 [SEP] 토큰이 없으므로 학습 시 이 토큰에 의존한 패턴을 학습하면 추론 성능이 저하될 수 있습니다. 만약 테스트 데이터에도 동일하게 [SEP] 토큰을 삽입한다면 고려할 수 있으나, 문장 부호 기준 분할 로직이 테스트 데이터에서 오작동할 위험이 있습니다. 길이 증가로 인한 계산 비용도 무시할 수 없습니다.\n",
    "\n",
    "**전략3(50%는 줄바꿈, 나머지 50%는 줄바꿈 없음)** 는 50% 대화는 줄바꿈을 적용하고 나머지 50%의 대화는 줄바꿈 없는 형식으로 모델을 학습시키는 전략입니다. 줄바꿈의 적용 유무가 모델 성능에 어떤 영향을 미칠지 실험하고자 고안하였습니다. 이 전략은 실험 차원에서 고안된 전략으로 실제 평가를 위해서는 모델을 생성하여 실제 성능을 평가하는 절차가 필요해 보입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42847e50",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
